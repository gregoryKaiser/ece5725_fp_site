
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>It's Dangerous To Go Alone</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">It's Dangerous To Go Alone...</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#drawings">Drawings</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
            <li><a href="#conclusion">Conclusion</a></li>
            <li><a href="#future">Future Work</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
      <div class="starter-template">
        <h1>ECE 5725 Final Project: It's Dangerous To Go Alone</h1>
        <p class="lead">
          An interactive game concept. <br>By: Gregory Kaiser (ghk48) and Caeli MacLennan (cam476). <br> December 18<sup>th</sup> 2020.
        </p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id='obj'>
      <div class="row">
          <!-- <div class="col-md-4" style="text-align:center;">
          <img class="img-rounded" src="pics/1.jpg" alt="Generic placeholder image" width="240" height="240">
          </div> -->
          <div class="col-md-8" style="font-size:18px;">
          <h2>Project Objective:</h2>
          <p style="text-align: left;padding: 0px 30px;">
            The objective of "It's Dangerous To Go Alone" is to demonstrate an interactive adventure game which requires 
            one to obtain items through the detection of real objects using a Raspberry Pi (RPi) camera. We wanted to exercise our object-oriented programming skills to develop a starting point for future game level design and feature
            additions. Additionally, we sought to demonstrate
            a remote connection for two Raspberry Pi's to communicate, allowing for a fun game to be played while social distancing in 2020. 
          </p>
          </div>
      </div>

      <hr id="intro">
      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Playing adventure games is a lot of fun, especially when the world is so absorbing that one gets lost in the universe's rules and quirky limitations.
                From the touchscreen of the original Nintendo DS, to the motion-controls of the Wii platform, however, there are a number of examples of novel user 
                input that demonstrate its utility and potential for better user engagement. Along these lines, we wanted items in our game to be acquired by finding similar
                items in real life that are recognized by a camera system. Thanks to recent developments in image processing and machine learning, we can use a lightweight 
                object detection model to pick up on a limited set of real objects, and then spawn them for use by the character. We also attempted to make this project multiplayer by trying a few methods of data transfer over our home networks.
              </p>
      </div>

    <hr id='design'>
      <div style="text-align:center;">
              <h2>Design</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Our design for this project occurred mostly in software, where we tried to make an expandable platform for generic level creation.
                Some changes were made in order to ensure that the camera was oriented correctly in-game, but we otherwise had very little trouble interfacing
                with the camera module.
              </p>
              <h3>Hardware</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Though we originally had aspirations for a more interesting hardware setup, the end-product consists of just a RPi and camera module. The camera's 
                ribbon cable is wrapped around the body of the RPi case and is mounted to its underside. The device is held in both hands, in a portrait orientation 
                with the piTFT buttons on the right side.
              </p>
              <h3>PyGame and Class Design</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Object types and functionality</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <hr id='userinput'>
              <h4>User input</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The piTFT provides the full user interface for a player. Two of the buttons are used for moving the character right and left, by 
                triggering callback functions that call the character's movement member functions. These buttons are denoted by icons displayed next to them
                on-screen. 
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">move_hero_left</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> hero
    <span style="color: #008800; font-weight: bold">global</span> move_l_toggle
    <span style="color: #008800; font-weight: bold">if</span> move_l_toggle <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span>:
        move_l_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
        hero<span style="color: #333333">.</span>moveLeft()
    <span style="color: #008800; font-weight: bold">else</span>:
        move_l_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
        hero<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">move_hero_right</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> hero
    <span style="color: #008800; font-weight: bold">global</span> move_r_toggle
    <span style="color: #008800; font-weight: bold">if</span> move_r_toggle <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span>:
        move_r_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
        hero<span style="color: #333333">.</span>moveRight()
    <span style="color: #008800; font-weight: bold">else</span>:
        move_r_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
        hero<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>

GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">23</span>, GPIO<span style="color: #333333">.</span>BOTH, callback<span style="color: #333333">=</span>move_hero_left, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">27</span>, GPIO<span style="color: #333333">.</span>BOTH, callback<span style="color: #333333">=</span>move_hero_right, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
</pre></div>
<br>
              <p style="text-align: left;padding: 0px 30px;">  
                The RPi.GPIO library is used to connect these buttons to their
                functionality, and they are triggered using both the rising and falling edge of the button signal. This way, when the button is pressed down, the
                character moves in one direction, and when it is released, the character is halted. By tapping on the touchscreen, the character jumps in the air. This function is controlled through the main game logic where the touch event is detected through polling.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Another piTFT button is used to trigger a callback function that switches control to the camera on the back of the device. This changes the game state to 
                detect objects for the user to acquire in-game. The final button on the "top" of the piTFT (closest to the power source) is a simple quit button to allow the user to end the game entirely.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">switch_state</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> GAME_STATE
    <span style="color: #008800; font-weight: bold">global</span> GAME_PLAY
    <span style="color: #008800; font-weight: bold">global</span> OBJ_DETECT
    <span style="color: #008800; font-weight: bold">global</span> obj_capture
    <span style="color: #008800; font-weight: bold">if</span> GAME_STATE<span style="color: #333333">==</span>GAME_PLAY:
        GAME_STATE <span style="color: #333333">=</span> OBJ_DETECT
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>OBJ_DETECT:
        GAME_STATE <span style="color: #333333">=</span> GAME_PLAY
        <span style="color: #008800; font-weight: bold">if</span> (<span style="color: #000000; font-weight: bold">not</span> obj_capture<span style="color: #333333">==</span><span style="background-color: #fff0f0">&quot;none&quot;</span>):
            drop_item_noncb() <span style="color: #888888">#spawn an object</span>

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">quit_game</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> run
    run <span style="color: #333333">=</span> <span style="color: #007020">False</span>

GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">22</span>, GPIO<span style="color: #333333">.</span>FALLING, callback <span style="color: #333333">=</span> switch_state, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">17</span>, GPIO<span style="color: #333333">.</span>FALLING, callback<span style="color: #333333">=</span>quit_game, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
</pre></div>
<br>
              <p style="text-align: left;padding: 0px 30px;">
                Of course, the player is also responsible for finding items in real life for the game to detect, and experimenting to find our limited set of detectable objects.
              </p>
              <hr id='collisions'>
              <h4>Collision logic</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <hr id='objdetect'>
              <h3>Object Detection with TensorFlow-Lite</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Objects are detected using TensorFlow-Lite by following closely a tutorial from <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">EdjeElectronics</a>. TensorFlow can be used for a lot of different machine learning tasks, and can be trained for this specific application of object detection from a RPi using an attached camera. Because this kind of process is computationally intensive, a more mobile and IoT-friendly version called <a href="https://www.tensorflow.org/lite" target="_blank">TensorFlow Lite</a> is used. 
              </p>
              <h4>Tutorial-based setup</h4>
              <p style="text-align: left;padding: 0px 30px;">
                In this <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">tutorial</a>, the Raspberry Pi is first updated in order to run the appropriate testing scripts.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo apt-get update</span>
<span style="color: #888888">sudo apt-get dist-upgrade</span>
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                One can then either clone our repository, or follow the tutorial instructions to acquire the necessary files for the next steps. In order to test the object detection itself, the tutorial github repository has example scripts which can confirm that the necessary pieces
                are in place and working properly.<br><br>
                First, a virtual environment is set up to separate potential package conflicts between the RPi and the libraries required for TFLite. These required dependencies are then acquired through a script provided by the tutorial. From inside the cloned repository (whichever was chosen), the following is executed:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo pip3 install virtualenv</span>
<span style="color: #888888">sudo python3 -m venv tflite1-env</span>
<span style="color: #888888">source tflite1-env/bin/activate</span>
<span style="color: #888888">sudo bash get_pi_requirements.sh</span>
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                Be sure that the virtual environment is activated before running the bash script by noticing that <code>(tflite1-env)</code> now appears before the username in the terminal, like this: <code>(tflite1-env) pi@ghk48-cam476:~/git/ece5725_fp $</code>. A pre-trained model with a number of common detectable objects is used by our script, which can either be downloaded by cloning our repository, or issuing the following:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip</span>
<span style="color: #888888">unzip coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d Sample_TFLite_model</span>
</pre></div><br>

              <h4>Wheezy downgrade</h4>
              <p style="text-align: left;padding: 0px 30px;">
                Because the update mentioned above causes issues when using pygame to control the piTFT, the downgrade performed in Lab 2 of ECE 5725 is repeated.<br><br>
                [TODO: condensed wheezy downgrade explanation??] <br><br>
                Once the necessary file changes are made, the wheezy downgrade can be installed.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo apt-get update</span>
<span style="color: #888888">sudo apt-get –y –-allow-downgrades install libsdl1.2debian/wheezy</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Now that all of the necessary parts are in place, once can attempt to run the single-player script. If additional libraries are missing, either try downloading them individually using <code>pip3</code>, or running the <code>get_pi_requirements.sh</code> script again. Sometimes that particular script will fail to download everything on the first try. The game itself is run with the following command:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo python3 game_and_detect_update.py --modeldir=Sample_TFLite_model --resolution=240x320</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>modeldir</code> argument points the script to the object detection model that one is using. The tutorial that we followed separated this from the main script such that custom models could be generated and stored in separate folders. This makes the system more modular, in case custom image-detection is developed. The <code>resolution</code> argument gives the resolution of the piTFT to the object detection script so that the camera image is scaled to fill the correct dimensions of the screen. These coordinates are also flipped (from 320x240) to compensate for the rotation of the camera before display, described in the section below.
              </p>
              <h4>Adapted to run on the piTFT screen</h4>
              <p style="text-align: left;padding: 0px 30px;">
                At first, we tried a different option for object detection which runs natively on the piTFT from <a href="https://learn.adafruit.com/running-tensorflow-lite-on-the-raspberry-pi-4?view=all" target="_blank">Adafruit</a>, but we found that the model was much less reliable on common objects, and had an extremely limited set of items compared to the tutorial described above. The critical flaw in the better model was that it crashed the RPi when trying to run on the piTFT using <code>cv2</code>. A workaround for this was required.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The object detection section of our game is nearly identical to the tutorial script called <code>TFLite_detection_webcam.py</code>, with a few changes. One of the main changes is to switch from using the <code>cv2</code> library to display camera output, to using pygame to display to the piTFT. In order to do this, we found a great resource from a past <a href="https://courses.ece.cornell.edu/ece5990/ECE5990_Fall15_FinalProjects/Andre_Heil/ece5990_final_report/avh34_jr986.html" target="_blank">ECE 5990 student project</a> for a face-recognition system. They used the cv2 library to write to a temporary file, which is then read back in and displayed in the usual pygame fashion by blitting to the display surface and updating periodically. The frame itself is also rotated 90 degrees to match the orientation of the camera since it is wrapped around the side, instead of the top, of our RPi console.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#ghk48: rotate to align with our setup</span>
frame <span style="color: #333333">=</span> cv2<span style="color: #333333">.</span>rotate(frame, cv2<span style="color: #333333">.</span>cv2<span style="color: #333333">.</span>ROTATE_90_COUNTERCLOCKWISE)

<span style="color: #888888">#ghk48: write to temp file so pygame can read and display</span>
cv2<span style="color: #333333">.</span>imwrite(<span style="background-color: #fff0f0">&#39;./tmp.bmp&#39;</span>, frame) <span style="color: #888888">#write frame</span>
img <span style="color: #333333">=</span> pygame<span style="color: #333333">.</span>image<span style="color: #333333">.</span>load(<span style="background-color: #fff0f0">&#39;./tmp.bmp&#39;</span>) <span style="color: #888888">#read frame</span>
win<span style="color: #333333">.</span>fill((<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>)) <span style="color: #888888">#clear screen</span>
win<span style="color: #333333">.</span>blit(img, (<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>)) <span style="color: #888888">#add frame</span>
pygame<span style="color: #333333">.</span>display<span style="color: #333333">.</span>update()
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                The other major change is the capture of a single label from every frame during detection, and storing it in a global variable (<code>obj_capture</code>) for use in-game once control 
                is handed back to the player. Since we are gating for just the first label in the list of detected objects (<code>classes_obj[0]</code>) which meets a minimum detection threshold, it is recommended that the user try to have only a single type of object detected in-frame when the game state is switched back to the character-controlled screen. When control returns (see <code>switch_state</code> under <a href="#userinput">User input</a>), the detected object is compared to the labels stored in three lists: one to acquire armor in the game, one for the weapon, and one for the apple. If the detected label is in one of these lists, an item is spawned in game with the appropriate characteristics and image asset. 
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">if</span> (<span style="color: #007020">len</span>(scores)<span style="color: #333333">&gt;</span><span style="color: #0000DD; font-weight: bold">0</span> <span style="color: #000000; font-weight: bold">and</span> (scores[<span style="color: #0000DD; font-weight: bold">0</span>]<span style="color: #333333">&gt;</span>min_conf_threshold)):
    obj_capture <span style="color: #333333">=</span> labels[<span style="color: #007020">int</span>(classes_obj[<span style="color: #0000DD; font-weight: bold">0</span>])]
<span style="color: #008800; font-weight: bold">else</span>:
    obj_capture <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&quot;none&quot;</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Because the object detection is based on a pre-trained model, the potentially detected labels are contained in a text file listing inside the folder <code>Sample_TF_Lite_model</code>. For the apple object to spawn, an "apple", "banana", or "orange" must be in-frame and detected. For a piece of armor, an "umbrella", "tie", or "backpack", will do. Finally, in order to get a dagger in the game, a "knife" or "scissors" must be visible and detected. 
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#recognizable objects taken from &quot;lablemap.txt&quot; in Sample_TFLite_model</span>
recog_knife <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;knife&quot;</span>, <span style="background-color: #fff0f0">&quot;scissors&quot;</span>]
recog_fruit <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;apple&quot;</span>,<span style="background-color: #fff0f0">&quot;banana&quot;</span>,<span style="background-color: #fff0f0">&quot;orange&quot;</span>]
recog_armor <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;umbrella&quot;</span>,<span style="background-color: #fff0f0">&quot;backpack&quot;</span>,<span style="background-color: #fff0f0">&quot;tie&quot;</span>]

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">drop_item_noncb</span>():
    <span style="color: #008800; font-weight: bold">global</span> all_objects
    <span style="color: #008800; font-weight: bold">global</span> disp_objects
    <span style="color: #008800; font-weight: bold">global</span> obj_capture
    <span style="color: #008800; font-weight: bold">if</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_knife):
        knife <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>weapon(knife_im_l, knife_im, <span style="background-color: #fff0f0">&quot;knife&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #007020">True</span>, <span style="color: #0000DD; font-weight: bold">10</span>) <span style="color: #888888">#new item</span>
        knife<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(knife) <span style="color: #888888">#add to screen</span>
    <span style="color: #008800; font-weight: bold">elif</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_fruit):
        apple <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>item(apple_im, <span style="background-color: #fff0f0">&quot;apple&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #007020">False</span>) <span style="color: #888888">#new item</span>
        apple<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(apple) <span style="color: #888888">#add to screen</span>
    <span style="color: #008800; font-weight: bold">elif</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_armor):
        shirt <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>armor(armor_im, <span style="background-color: #fff0f0">&quot;armor&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">15</span>, <span style="color: #0000DD; font-weight: bold">15</span>, <span style="color: #007020">True</span>, <span style="color: #0000DD; font-weight: bold">10</span>, <span style="background-color: #fff0f0">&quot;cold&quot;</span>, <span style="background-color: #fff0f0">&quot;torso&quot;</span>) <span style="color: #888888">#new item</span>
        shirt<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(shirt) <span style="color: #888888">#add to screen</span>
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                These were the most appropriate labels that the model was already trained upon, so the player must find these objects through trial and error. While it takes time, training one's own custom model is also possible, and is explained by <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">EdjeElectronics</a> in their very informative tutorial.
              </p>
              <h3>Main game logic and structure</h3>
              <h4>Game state-machine</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The game state machine cycles through just a few possible game states. The first is the title screen, which merely shows the title of the game in basic
                text near the middle of the piTFT. The second game state is the main playable section, with a moveable character, item acquisition, collision detection, and
                environmental effects. The third game state is the object-detection phase, which is triggered when a user presses the appropriate button on the piTFT. This state
                displays the camera's view on the piTFT and draws bounding boxes around detected objects in-frame using TensorFlow-Lite. Pressing the same button that triggered this state hands control back to the second game state, where the player gains control of their character again. Finally, the end screen state shows the "You Died" text, indicating that the game is lost. The end of the game is triggered by either 1) a loss of all of one's health or 2) falling off of the level 1 platform, and therefore off-screen. This game state also clear's the character's inventory in order to respawn the hero back onto the screen.<br><br>
                In pseudo-code form, the basic format is shown below:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#finite state machine</span>
GAME_STATE <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">4</span>
GAME_PLAY <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
OBJ_DETECT <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">2</span>
END_SCREEN <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">3</span>
MENU_SCREEN <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">4</span>

<span style="color: #008800; font-weight: bold">while</span> run : <span style="color: #888888">#main game loop</span>
    clock<span style="color: #333333">.</span>tick(<span style="color: #0000DD; font-weight: bold">40</span>)
    <span style="color: #008800; font-weight: bold">if</span> GAME_STATE<span style="color: #333333">==</span>MENU_SCREEN:
        <span style="color: #888888">#display main title</span>
        <span style="color: #888888">#delay for a couple seconds</span>
        GAME_STATE <span style="color: #333333">=</span> GAME_PLAY
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>END_SCREEN:
        <span style="color: #888888">#display end screen with appropriate delays</span>
        <span style="color: #888888">#reset hero and add back to the displayable objects</span>
        GAME_STATE <span style="color: #333333">=</span> MENU_SCREEN
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>GAME_PLAY:
        <span style="color: #888888">#check for touchscreen press to trigger jump</span>
        <span style="color: #888888">#check for environment match to decrement health</span>
        <span style="color: #888888">#check for end state based on health&lt;=0 or y-position below the &quot;floor&quot;</span>
            <span style="color: #888888">#clear item inventory if the hero has died</span>
            <span style="color: #888888">#remove the hero itself</span>
            GAME_STATE <span style="color: #333333">=</span> END_SCREEN
        <span style="color: #888888">#move everything in the x direction</span>
        <span style="color: #888888">#check for x collisions</span>
        <span style="color: #888888">#move everything in the y direction</span>
        <span style="color: #888888">#check for y collisions</span>
        <span style="color: #888888">#update the screen</span>
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>OBJ_DETECT:
        <span style="color: #888888">#perform object detection with tutorial example</span>
        <span style="color: #888888">#draw all boxes around detected objects</span>
        <span style="color: #888888">#grab the first detected object for spawning items</span>
        <span style="color: #888888">#write the frame rate on the frame, rotate it 90 degrees, and store in a temporary file</span>
        <span style="color: #888888">#read in the frame with pygame, blit onto the screen, and update the display.</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Note that the object detection phase can only be triggered by a button press on the third button from the "bottom" of the piTFT. Through this game state logic, the entire game is controlled by the single user. Please see the description of the game logic itself in the section above, or feel free to read through the source code to see everything in action. The demonstration video linked at the top of the page should also give a good sense of how the game state switching operates.
              </p>
              <h4></h4>
              <p style="text-align: left;padding: 0px 30px;">
                While the menu screen and the end title are not worth detailing here (they consist of a simple text render and pygame display), the <code>GAME_PLAY</code> and <code>OBJ_DETECT</code> states are worth a bit more explanation. The <code>GAME_PLAY</code> state relies on helper functions described in the <a href="#collisions">Collision Logic</a> section and defined in <code>classes.py</code>. After checking for a touch input, which triggers the hero's y-velocity to be set high, and after checking the environment against the hero's equipment (at a 3-second interval) to decrement health, the displayable objects are "moved" in the x direction based on their speed. Collisions due to this move are checked, and those movements are reversed if a collision occurs. They are then "moved" in the y-direction, checked for collisions, and reversed if necessary again. This effectively carries out the physics of our game, which first changes the position of the objects on-screen before showing that frame on the screen.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>OBJ_DETECT</code> phase follows the tutorial described in <a href="#objdetect">the object detection description</a> through the following process. First, a frame is taken from the video stream, which is an instance of a class designed by <a href="https://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/" target="_blank">Adrian Rosebrock</a> of PyImageSearch. This frame is resized and normalized as a preparation step for feeding into the TFLite model before detection is "performed." The results are stored, along with bounding boxes around the detected objects. For all of these detections, the results of the detection are used to draw boxes around, and label, those objects which the model is over 50% confident are in-frame. The label of the first object is stored for our game script, and then the frame, with bounding boxes, is stored ina temporary file and re-displayed by pygame, as desribed earlier.
              </p>
              <h3>Remote Connection Attempts</h3>
              <p style="text-align: left;padding: 0px 30px;">
                To expand the game to be a multiplayer experience, we tried multiple different methods which relied on the same basic example script that we wanted to adapt to our purposes. We tried to follow a set of tutorials from someone named TechWithTim, who maintains a website and a set of YouTube videos that detail the creation of web server and client python scripts. Our strategy was to run these examples to establish a connection first, and then adapt the game to work over the confirmed connection. The scripts use the <code>socket</code> and <code>pickle</code> libraries to connect two machines together.
              </p>
              <h4>Attempt 1: Opening a port on a home network</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Attempt 2: Host a server on a port on the class server</h4>
              <p style="text-align: left;padding: 0px 30px;">
                We also attempted to host a server on one RPi through the class server by opening a reverse ssh tunnel. First, we ran the following command in the terminal of either our laptop or the first RPi:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">ssh -R 1000:localhost:4000 <span style="color: #333333">[</span>netid<span style="color: #333333">]</span>@132.236.79.205
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                This opens a connection between port 4000 on the device that issued the command, and opens port 1000 on the class server. To check that this connection is open and correct, Anthony Ngoma, a generous classmate, provided the following command which lists open ports on the class server:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">netstat -tulpn 
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Once the creation of that open port was confirmed, we attempted to use the -L option of the ssh command to open a connection to a second device, this time from port 2000 on the second device, to the now open port 1000 on the class server:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">ssh -L 2000:localhost:1000 <span style="color: #333333">[</span>othernetid<span style="color: #333333">]</span>@132.236.79.205
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                The server script is run on the first device, while the client script is run on the second device. We fed every permutation of IPv4 addresses to the scripts, as well as every port combination that we thought might solve the issue. However, no matter which ports we chose, which devices we tried to connect (even trying to connect a device to itself), nor what order of operations these commands followed, we were unable to establish a connection over the class server in this manner. Usually, the connection was rejected, giving us suspicion that the IP address or port numbers were incorrect. Sometimes, the connection merely timed out, indicating to us that our settings were likely correct, but that for some reason the connection was never fully established.
              </p>
              <h4>Attempt 3: Package and send data locally to demonstrate intent</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The last option was an attempt to, at the very least, show what our intent was with respect to packaging game data. The examples from TechWithTim were good, but were quite simplistic, including a game that transferred the positions of two red boxes on-screen in a small and very specific format. To pack our entire set of displayable game objects and send them over a network, we decided to use the pickle library. By following some online examples, as well as a very valuable forum post, we generated three scripts that run a single client-server line of communication. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>desktop_server.py</code> script creates a custom <code>Server</code> object to collect game data and display it in a window. It waits for a connection to a client, continuously recieves game data, and merely shows where those objects are on-screen, without the ability to control them.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>desktop_client.py</code> script creates a custom <code>Client</code> object which connects a desktop version of our game in a primitive form. User input is adapted to allow the use of the keyboard to move the player, and all game logic is performed locally in this script. At the end of a frame, <code>pickle</code> is used to package and send the entire displayable objects list to the server for display on the other end. The <code>rpi_client.py</code> script runs on the same logic as <code>desktop_client.py</code>, except that it can run without issue on the RPi, and the usual piTFT buttons can be used to control the game. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Because <code>pickle</code> is not capable of packaging pygame surfaces, our original <code>classes.py</code> script needed to be adapted to <code>classes_multi.py</code>, which instead stores image file paths instead of a pre-generated pygame surface. Every time an object is drawn, the pygame surface can then be made locally on either the client or the server side to show it in a window.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                This multiplayer functionality, due to the fact that it is in the very preliminary stages of development, is contained within a separate <code>multiplayer</code> folder on our github page. By running first <code>sudo python3 desktop_server.py</code> on <i>either</i> the RPi or on a laptop, and then running <code>sudo python3 rpi_client.py</code> or <code>python desktop_client.py</code> <i>on the same machine</i>, a connection is established over a local network. This shows that the data sent by pickle is being packed, sent, and recieved without error. While this connection runs well on a laptop, there is some lag while running both scripts on the RPi, probably because the pygame surfaces are re-created every time an object is drawn, instead of being made once upon the intiialization of an object instead.
              </p>
      </div>

    <hr id='drawings'>
      <div style="text-align:center;">
              <h2>Drawings</h2>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]This is the drawings section.
              </p>
      </div>

    <hr id='testing'>
      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]This is the testing section. Mention vs code workflow here as well
              </p>
              <h3>Gravity and Drag and Collisions</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h3>Camera and well-detected objects</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h3>Multiplayer testing/debugging</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
      </div>

    <hr id='result'>
      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]This is the results section. 
              </p>
      </div>

    <hr id='conclusion'>
      <div style="text-align:center;">
              <h2>Conclusion</h2>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]This is the conclusion section.
              </p>
      </div>

    <hr id='future'>
      <div style="text-align:center;">
              <h2>Future Work</h2>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]This is the future work section.
              </p>
              <h3>Expanding the game</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Camera movement</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Multiple levels/environments</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Enemies and other moving assets</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Custom TensorFlow-Lite model</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h4>Menu Screen, Game Score, and Inventory Access</h4>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
              <h3>Extension to multiplayer</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [TODO]
              </p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group_photo.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Group picture of Caeli and Greg.</h4>
              <p>
                All synchronous work was done over zoom using other collaboration tools like the Live Share feature of VS Code as well as github and Google Drive. A lot of asynchronous work was done due to scheduling conflicts and the time difference between the east and west Coast<br><br>
                <b>Group responsibilities:</b>
                  <li>High level design decisions and division of labor.</li>
                  <li>Class and game logic design.</li>
                  <li>Image asset collection.</li>
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/caeli_pic.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Caeli MacLennan</h3>
              <p class="lead">cam476@cornell.edu</p>
              <p>
                [describe contributions in paragraphical or list form]
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
              <h3>Gregory Kaiser</h3>
              <p class="lead">ghk48@cornell.edu</p>
              <p>
                <li>Designed the state machine and menu cycle.</li>
                <li>Developed and tested TFLite capabilities and integrated them into game logic.</li>
                <li>Adapted TFLite to run on the piTFT, and designed item spawning logic (checking for detected objects).</li>
                <li>Attempted to host a web server on the class server using ssh commands (Attempt 2).</li>
                <li>Wrote desktop_server.py, desktop_client.py, and rpi_client.py to establish object transfer over local network (Attempt 3).</li>
                <li>Edited demonstration video.</li>
              </p>
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li><a href="https://www.adafruit.com/product/1601" target="_blank">Adafruit PiTFT 1.8'' TFT and Touchscreen</a> $35.00</li>
              <li><a href="https://www.amazon.com/Raspberry-Pi-Camera-Module-Megapixel/dp/B01ER2SKFS/ref=sr_1_3?dchild=1&keywords=raspberry+pi+camera&qid=1608266423&sr=8-3" target="_blank">Raspberry Pi Camera V2</a> $25.00</li>
          </ul>
          <h3>Total: $95.00</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="http://www.micropik.com/PDF/SG90Servo.pdf">Tower Pro Servo Datasheet</a><br>
          <a href="http://getbootstrap.com/">Bootstrap</a><br>
          <a href="http://abyz.co.uk/rpi/pigpio/">Pigpio Library</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>

      </div>
      <div style="font-size:18px">
          <h2>Image sources</h2>[TODO]
      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>[TODO]
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->

    <!-- <figure>
      <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
      <figcaption>hello</figcaption>
    </figure> -->



    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
