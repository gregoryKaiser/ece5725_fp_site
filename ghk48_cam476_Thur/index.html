
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>It's Dangerous To Go Alone</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">It's Dangerous To Go Alone...</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
            <li><a href="#conclusion">Conclusion</a></li>
            <li><a href="#future">Future Work</a></li>
            <li><a href="#BOM">Budget</a></li>
            <li><a href="#references">References</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
      <div class="starter-template">
        <h1>ECE 5725 Final Project: It's Dangerous To Go Alone</h1>
        <p class="lead">
          An interactive game concept. <br>By: Gregory Kaiser (ghk48) and Caeli MacLennan (cam476). <br> December 18<sup>th</sup> 2020.
        </p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/embed/vWkzyjgylwI" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id="obj">
      <div style="text-align:center;">
              <h2>Project Objective</h2>
              <p style="text-align: left;padding: 0px 30px;">
                The objective of "It's Dangerous To Go Alone" is to demonstrate an interactive adventure game which requires 
                one to obtain items through the detection of real objects using a Raspberry Pi (RPi) camera. We wanted to exercise our object-oriented programming skills to develop a starting point for future game level design and feature
                additions. Additionally, we sought to demonstrate
                a remote connection for two Raspberry Pi's to communicate, allowing for a fun game to be played while social distancing in 2020. 
              </p>
      </div>

      <hr id="intro">
      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Playing adventure games is a lot of fun, especially when the world is so absorbing that one gets lost in the universe's rules and quirky limitations.
                From the touchscreen of the original Nintendo DS, to the motion-controls of the Wii platform, however, there are a number of examples of novel user 
                input that demonstrate its utility and potential for better user engagement. Along these lines, we wanted items in our game to be acquired by finding similar
                items in real life that are recognized by a camera system. Thanks to recent developments in image processing and machine learning, we can use a lightweight 
                object detection model to pick up on a limited set of real objects, and then spawn them for use by the character. We also attempted to make this project multiplayer by trying a few methods of data transfer over our home networks.
              </p>
      </div>

    <hr id='design'>
      <div style="text-align:center;">
              <h2>Design</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Our design for this project occurred mostly in software, where we tried to make an expandable platform for generic level creation.
                Some changes were made in order to ensure that the camera was oriented correctly in-game, but we otherwise had very little trouble interfacing
                with the camera module.
              </p>
              <h3>Hardware</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Though we originally had aspirations for a more interesting hardware setup, the end-product consists of just a RPi and camera module. The camera's 
                ribbon cable is wrapped around the body of the RPi case and is mounted to its underside. The device is held in both hands, in a portrait orientation 
                with the piTFT buttons on the right side.
                <figure>
                <img class="img-rounded" src="pics/rpi_front.jpg" alt="RPi front" style="width:40%;">
                <img class="img-rounded" src="pics/rpi_back.jpg" alt="RPi front" style="width:40%;">
                <figcaption>The Raspberry Pi with attached camera module. The device is held in the orientation shown on the left. On the right, the module is taped in place.</figcaption>
                </figure><br></p>
              <p style="text-align: left;padding: 0px 30px;">
                Our original idea had much higher expectations for the final result, but our overall implementation was similar:
                <figure>
                <img class="img-rounded" src="pics/concept_art_1.jpg" alt="RPi front" style="width:40%;">
                <img class="img-rounded" src="pics/concept_art_2.jpg" alt="RPi front" style="width:15%;">
                <figcaption>Sketches in the early stages of the project set a high bar for the hardware implementation.</figcaption>
                </figure><br>
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The camera ribbon cable itself was carefully inserted into the appropriate slot on the RPi before re-installing the PiTFT.
                <figure>
                <img class="img-rounded" src="pics/rpi_side_open.jpg" alt="RPi front" style="width:30%;">
                <img class="img-rounded" src="pics/rpi_camera_connection.jpg" alt="RPi front" style="width:20%;">
                <figcaption>The ribbon cable has a specific orientation and is inserted carefully before wrapping it around the RPi case.</figcaption>
                </figure><br>
              </p>
              <h3>PyGame and Class Design</h3>
              <p style="text-align: left;padding: 0px 30px;">
                For ease of game design and object addition, each object was implemented as a class with uniquely defined member functions for each type of object. 
                Functions which function on all objects in the same manner were defined below the object classes. 
                Below is an in-depth description of each function and class. Note that each class has a draw member function that draws the objects at the correct
                location on the screen.
              </p>
              <h4>Classes</h4>
              <p style="text-align: left;padding: 0px 40px;">
                <b>Character</b>
              </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The character class is meant to store the hero player and give them the ability to make changes upon
                  their environment, as well as to allow the environment to make changes to the hero. To determine where
                  to blit the character onto the screen, the character class has an x and y member field, which correspond
                  to the character's current x and y screen coordinates. To store the character's location relative to the 
                  game map, the character class also has <code>global_x</code> and <code>global_y</code> member fields. These fields are most relevant
                  when the character reaches the edge of the screen, and the screen must adjust so the character can 
                  continue. Because our demo only had one level that did did not extend beyond the edge of the screen, these fields 
                  represent the character's starting position. Finally, the character needs to update their position when the move function is called. To
                  determine how much the position should be updated, the character has an x and y speed, which correspond
                  to the number of pixels added to the x and y positions when the move function is called.
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  For determining the character's hitbox, which is defined as the area wherein collisions will be detected,
                  the character has a width and a height. These are both measured in pixels. The hitbox is stored as a four 
                  value tuple of the character's x, y, width, and height. These four parameters are all that is needed to 
                  determine the collision window, or hitbox. Width, height, and hitbox are all stored as member fields. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  To store the image used to display the character on the screen the character class has two member fields: 
                  a left image field and a right image field. This allows for the character to face the direction they are
                  moving, which is kept track of using the direction member field. In single player mode, these fields store 
                  pygame image objects, but in the multiplayer version they store image paths for ease of file transfer. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The above mentioned member fields cover the basic necessities of displaying the character, keeping track of
                  their location, deciding their collision window and storing their speed. The following member functions allow 
                  the character to retain effects from environment interactions.
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The health member field of the character is initialized to 100 and stores the amount of health the character
                  has. This value can be modified when the character collides with certain objects, as will be discussed later.
                  The attack member field stores the attack value of the last weapon item the hero collided with, while the defense
                  member field stores the defense value of the last armor item the character collided with. The inventory member field 
                  stores a list of the names of the items the character has collided with. Finally, the <code>env_type</code>
                  member field stores the environment type of the last item the hero collided with. The item, weapon and armor classes
                  will be discussed later in this section. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The last member fields included in the character class are <code>physics_on</code> and signaling. The field <code>physics_on</code> stores an integer key 
                  which will be used later in the collision function to determine how the object should react upon a collision. The signaling
                  member field was not implemented in the single player version, but would be used to indicate when the character is signaling
                  to the god player that they need an item to be dropped into the game.
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  To control the character, the member functions <code>moveRight</code>, <code>moveLeft</code>, <code>jump</code>, and <code>stopMoving</code> and implemented to update the appropriate
                  speed and direction member fields. The stop_signal and signal memner functions are meant as part of the multiplayer implementation, and toggle 
                  the character's <code>signaling</code> field to 0 or 1. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                <b>Item</b>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The item class includes an <code>image</code>, <code>x</code>, <code>y</code>, <code>global_x</code>, <code>global_y</code>, <code>height</code>, <code>width</code>, and <code>physics_on</code> much like the character class. It also has a <code>speed_x</code> and 
                  <code>speed_y</code>, which would be set to the speed the background is moving when the character is pushing against the edge of the screen, and a <code>health</code>, which stores
                  the health delivered to the hero when the hero collides with the item. The item 
                  class is meant to store things that the hero can pick up, meaning objects of class item will dissappear or display on the character's person upon colliding with a character. This
                  is accomplished through the member field <code>picked_up</code>, which is initialized to <code>False</code> but is set to true in the collision function when the hero 
                  collided with that item.
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  An item's display after it is picked up is determined using the equippable member field. If an item is initialized with equippable set to True, 
                  logic in the member function draw will call draw_equipped and display the object on the body of the character that collides with it. Whether or not
                  the item has collided with a character is stored in the boolean <code>picked_up</code> member field. 
                </p>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                <b>Weapon</b>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The weapon class is a child of the item class. From its parent, the weapon class inherits the fields <code>image</code>, <code>name</code>, <code>x</code>, <code>y</code>, <code>global_x</code>, global_y, width, height, and equippable member fields.
                  In addition to the weapon's parent class fields, it also stores an <code>image_l</code> and <code>image_r</code> so that it may be pointing the same way as the hero when the hero turns and the weapon is equipped. 
                  Finally, the weapon has an attack parameter, the value of which could transfer to a character that collides with it. We did not implement this since no attacks were demonstrated in the demo. 
                  In addition to the draw function, the weapon class has a <code>draw_equipped</code> function that draws the weapon in front of the character after the character has collided with it. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                <b>Armor</b>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The armor class is also a child of the item class, and is almost identical to the weapon class except that it has a defense field instead of an attack field which also was not used due to the lack of enemies in our demo, and it also has an <code>env_type</code> member field,
                  which it gives to the character that collides with it. 
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                <b>Obstacle</b>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The obstacle class has the member fields <code>x</code>, <code>y</code>, <code>global_x</code>, <code>global_y</code>, <code>width</code>, <code>height</code>, <code>hitbox</code>, <code>speed_x</code>, <code>speed_y</code>, <code>env_type</code>, <code>image</code>, and <code>physics_on</code>. This class is meant to hold stationary objects such as
                  platforms that the character can jump on or needs to maneuver around. To prevent the object from being affected by gravity in the collision loop, "physics_on" is set to zero. The obstacle class also
                  has an env_type, which would allow for micro-environments to be implemented in the future such as a platform of ice or one of hot coals that the hero has to additionally be equipped for.     
                  </p>
                <p style="text-align: left;padding: 0px 40px;">
                <b>Environment</b>
                </p>
                <p style="text-align: left;padding: 0px 40px;">
                  The environment class is the only object that does not display on the screen, and is meant to create an invisible environment that the characters must be equipped for in order to avoid losing health. 
                  This class has a global_x position, an effect_length, a string "env_type", an attack, and a "physics_on" member field. Even though this object is not displayed, giving it a "physics_on" field allows it to be
                  handled the same as the other objects when handling collisions. The "attack" field stores an amount of health that could be decremented from all characters within the range of the environment that are not 
                  equipped for it. Our demo implements this health decrement differently in the main logic, but a game with more environments would likely use this field. Environments of type <code>none</code> do not decrement character health. 
                </p>
              </p>
              <h4>Non-Member Functions</h4>
              <p style="text-align: left;padding: 0px 40px;">
                <b>Collide</b>
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                The "Collide" function checks the passed list of objects for collisions in the passed direction, which is x or y. So if 'x' was passed as a direction, collide detects object collisions from objects moving horizontally,
                and if 'y' was passed then it would both check for collisions in the y direction. Object collisions between each other are checked in a recursive helper function called "find_collisions" that takes
                in the list of objects and returns a list of those that overlapped with another object's hitbox. Once the list of collided objects is returned, the main collide function handles object position adjustment in the appropriate
                direction.
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                <b>Move Objects</b>
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                The function to move objects, called "move_objs" takes a list of objects to move and a direction. When called, the function will move the objects by their x or y speed, depending on the direction passed, and will also implement
                the correct physics effects on each object such as gravity and drag. Gravity affects all objects with a "physics_on" member field greater than 0. If the viable object's speed is less than 20, the terminal velocity, the object's 
                speed is increased by two. Note that from the user's point of view, moving from the top of the screen to the bottom of the screen is moving in the positive y direction. Drag is implemented on all objects with non-zero speed, and
                works both to slow objects as they fall and to provide a friction effect for non-character objects when they fall into the game and land on the ground. Because the character's x speed is controlled by the toggling of a button, x drag 
                does not apply to the character. This is implemented by checking the object's "physics_on" parameter; only those objects with a physics of 1 will have x drag applied. 
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                <b>Redraw Window</b>
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                Redraw window handles clearing the screen and then blitting the objects and background onto the screen to allow for character animation. Redraw window also handles drawing of all the text on the screen. Objects are drawn by looping
                the displayable objects list and calling each object's draw function. In this loop each object is also checked to see if it is an item, since the item's draw function takes the hero argument in addition to the window argument. 
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                <b>Drop Item</b>
              </p>
              <p style="text-align: left;padding: 0px 40px;">
                The drop item function, called "drop_item_noncb", takes no arguments and is called when the game changes state between the "god" and "hero" mode. If the captured object is in the list of recognized objects, this function initializes
                the object and appends it to the displayable objects list so that it can be drawn in the following cycle. 
              </p>
              
              </p>
              <hr id='userinput'>
              <h4>User input</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The piTFT provides the full user interface for a player. Two of the buttons are used for moving the character right and left, by 
                triggering callback functions that call the character's movement member functions. These buttons are denoted by icons displayed next to them
                on-screen. 
              </p>
            
              
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">move_hero_left</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> hero
    <span style="color: #008800; font-weight: bold">global</span> move_l_toggle
    <span style="color: #008800; font-weight: bold">if</span> move_l_toggle <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span>:
        move_l_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
        hero<span style="color: #333333">.</span>moveLeft()
    <span style="color: #008800; font-weight: bold">else</span>:
        move_l_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
        hero<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">move_hero_right</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> hero
    <span style="color: #008800; font-weight: bold">global</span> move_r_toggle
    <span style="color: #008800; font-weight: bold">if</span> move_r_toggle <span style="color: #333333">==</span> <span style="color: #0000DD; font-weight: bold">0</span>:
        move_r_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
        hero<span style="color: #333333">.</span>moveRight()
    <span style="color: #008800; font-weight: bold">else</span>:
        move_r_toggle <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>
        hero<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">0</span>

GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">23</span>, GPIO<span style="color: #333333">.</span>BOTH, callback<span style="color: #333333">=</span>move_hero_left, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">27</span>, GPIO<span style="color: #333333">.</span>BOTH, callback<span style="color: #333333">=</span>move_hero_right, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
</pre></div>
<br>
              <p style="text-align: left;padding: 0px 30px;">  
                The RPi.GPIO library is used to connect these buttons to their
                functionality, and they are triggered using both the rising and falling edge of the button signal. This way, when the button is pressed down, the
                character moves in one direction, and when it is released, the character is halted. By tapping on the touchscreen, the character jumps in the air. This function is controlled through the main game logic where the touch event is detected through polling.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Another piTFT button is used to trigger a callback function that switches control to the camera on the back of the device. This changes the game state to 
                detect objects for the user to acquire in-game. The final button on the "top" of the piTFT (closest to the power source) is a simple quit button to allow the user to end the game entirely.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">switch_state</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> GAME_STATE
    <span style="color: #008800; font-weight: bold">global</span> GAME_PLAY
    <span style="color: #008800; font-weight: bold">global</span> OBJ_DETECT
    <span style="color: #008800; font-weight: bold">global</span> obj_capture
    <span style="color: #008800; font-weight: bold">if</span> GAME_STATE<span style="color: #333333">==</span>GAME_PLAY:
        GAME_STATE <span style="color: #333333">=</span> OBJ_DETECT
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>OBJ_DETECT:
        GAME_STATE <span style="color: #333333">=</span> GAME_PLAY
        <span style="color: #008800; font-weight: bold">if</span> (<span style="color: #000000; font-weight: bold">not</span> obj_capture<span style="color: #333333">==</span><span style="background-color: #fff0f0">&quot;none&quot;</span>):
            drop_item_noncb() <span style="color: #888888">#spawn an object</span>

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">quit_game</span>(channel):
    <span style="color: #008800; font-weight: bold">global</span> run
    run <span style="color: #333333">=</span> <span style="color: #007020">False</span>

GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">22</span>, GPIO<span style="color: #333333">.</span>FALLING, callback <span style="color: #333333">=</span> switch_state, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
GPIO<span style="color: #333333">.</span>add_event_detect(<span style="color: #0000DD; font-weight: bold">17</span>, GPIO<span style="color: #333333">.</span>FALLING, callback<span style="color: #333333">=</span>quit_game, bouncetime<span style="color: #333333">=</span><span style="color: #0000DD; font-weight: bold">100</span>)
</pre></div>
<br>
              <p style="text-align: left;padding: 0px 30px;">
                Of course, the player is also responsible for finding items in real life for the game to detect, and experimenting to find our limited set of detectable objects.
                <figure>
                <img class="img-rounded" src="pics/button_label.png" alt="RPi front" style="width:50%;">
                <figcaption>The button functions are labeled with icons that indicate their function. The entire touchscreen is used as a jump button, and game variables are displayed in the upper-left corner.</figcaption>
                </figure><br>
              </p>
              <hr id='collisions'>
              <h4>Collision logic</h4>
              <p style="text-align: left;padding: 0px 30px;">
                Implementing collision was tricky due to the large area of the objects colliding. To make collision checks efficient, rather that checking for collisions in all directions in one large check, the collision function
                was implemented to take a direction field as well. In the main game program, the move function was called in the x direction on all objects, then collisions were detected in the x direction, then the objects were moved
                in the y direction, and finally the y direction collisions were detected. This dual call structure requires fewer checks because the game does not have to consider the cases where an object is colliding with something but 
                should still be permitting movement, such as walking on the floor or jumping and hitting the side of a block. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Object collision in either direction is also broken up into two steps: detecting the objects that collided, and updating the object position. The first is handled by a recursive helper funciton called find_collisions,
                which takes an object list. Inside the function logic, the head object of the passed list is removed and compared with the remaining objects in the list. Any object found to collide with the initial object is removed from
                the passed list and appended to a seperate collision list. If the initial object collided with anything in the list, it is also appended to the collision list after being compared with all other objects in the passed list. 
                During these checks, the initial removed object is checked if it is a character or an item; if so, each subsequent object will be checked to determine if it is an item if the first object is a hero, or it will check to see if
                the subsequent objects are a character if the first was an item. Given a character-item collision, the item is added to the character's inventory field, and the item's "picked_up" field is set to true. The health 
                field of a generic item is also added to the health field of the character. If item is an armor item, the character's "env_type" field is updated to match that of the armor's "env_type" field. Once all of these checks are 
                finished and the objects have been added and removed from the appropriate lists, the function returns the list of collided objects plus a call to the helper function with the same list that was passed initially; since the
                found collided objects have already been removed from this list, only objects for which a collision was not yet found will be checked. The base case is triggered when the passed list of objects is empty, wherin it returns 
                list of collided objects. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                After the helper function is finished executing, a list of the collided objects is returned to the main collision function. The list of objects originally passed to the collide function is iterated through; if the object is
                also in the collided objects list, the objects x or y direction is edited, depending on the direction passed to the function. If checking for x collisions, the function will set moving objects back by their width in the reverse 
                direction the object was moving. This prevents objects from getting stuck to each other when they collide. In the y direction, collided objects will be have whatever move they just made reversed by subtracting the object's speed
                field from the object's y position. This is what prevents objects from falling through other objects. Finally, at the end of each iteration of the loop the object's hitbox is updated with the new x and y positions of the object. 

              </p>
              <p style="text-align: left;padding: 0px 30px;">


              </p>

              <hr id='objdetect'>
              <h3>Object Detection with TensorFlow-Lite</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Objects are detected using TensorFlow-Lite by following closely a tutorial from <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">EdjeElectronics</a>. TensorFlow can be used for a lot of different machine learning tasks, and can be trained for this specific application of object detection from a RPi using an attached camera. Because this kind of process is computationally intensive, a more mobile and IoT-friendly version called <a href="https://www.tensorflow.org/lite" target="_blank">TensorFlow Lite</a> is used. 
              </p>
              <h4>Tutorial-based setup</h4>
              <p style="text-align: left;padding: 0px 30px;">
                In this <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">tutorial</a>, the Raspberry Pi is first updated in order to run the appropriate testing scripts.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo apt-get update</span>
<span style="color: #888888">sudo apt-get dist-upgrade</span>
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                One can then either clone our repository, or follow the tutorial instructions to acquire the necessary files for the next steps. In order to test the object detection itself, the tutorial github repository has example scripts which can confirm that the necessary pieces
                are in place and working properly.<br><br>
                First, a virtual environment is set up to separate potential package conflicts between the RPi and the libraries required for TFLite. These required dependencies are then acquired through a script provided by the tutorial. From inside the cloned repository (whichever was chosen), the following is executed:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo pip3 install virtualenv</span>
<span style="color: #888888">sudo python3 -m venv tflite1-env</span>
<span style="color: #888888">source tflite1-env/bin/activate</span>
<span style="color: #888888">sudo bash get_pi_requirements.sh</span>
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                Be sure that the virtual environment is activated before running the bash script by noticing that <code>(tflite1-env)</code> now appears before the username in the terminal, like this: <code>(tflite1-env) pi@ghk48-cam476:~/git/ece5725_fp $</code>. A pre-trained model with a number of common detectable objects is used by our script, which can either be downloaded by cloning our repository, or issuing the following:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip</span>
<span style="color: #888888">unzip coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d Sample_TFLite_model</span>
</pre></div><br>

              <h4>Wheezy downgrade</h4>
              <p style="text-align: left;padding: 0px 30px;">
                Because the update mentioned above causes issues when using Pygame to control the piTFT, the downgrade to Raspbian Wheezy performed in Lab 2 of ECE 5725 is repeated. These steps are also detailed on Adafruit's <a href="https://learn.adafruit.com/adafruit-pitft-28-inch-resistive-touchscreen-display-raspberry-pi/pitft-pygame-tips" target="_blank">2.8'' PiTFT installation/use tutorial</a> which goes into some detail on the file changes required to use Pygame. A handy bash script there makes all of the necessary changes at once.<br><br>
                Once the necessary file changes are made, the wheezy downgrade can be installed.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo apt-get update</span>
<span style="color: #888888">sudo apt-get –y –-allow-downgrades install libsdl1.2debian/wheezy</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Now that all of the necessary parts are in place, once can attempt to run the single-player script. If additional libraries are missing, either try downloading them individually using <code>pip3</code>, or running the <code>get_pi_requirements.sh</code> script again. Sometimes that particular script will fail to download everything on the first try. The game itself is run with the following command:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">sudo python3 game_and_detect_update.py --modeldir=Sample_TFLite_model --resolution=240x320</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>modeldir</code> argument points the script to the object detection model that one is using. The tutorial that we followed separated this from the main script such that custom models could be generated and stored in separate folders. This makes the system more modular, in case custom image-detection is developed. The <code>resolution</code> argument gives the resolution of the piTFT to the object detection script so that the camera image is scaled to fill the correct dimensions of the screen. These coordinates are also flipped (from 320x240) to compensate for the rotation of the camera before display, described in the section below.
              </p>
              <h4>Adapted to run on the piTFT screen</h4>
              <p style="text-align: left;padding: 0px 30px;">
                At first, we tried a different option for object detection which runs natively on the piTFT from <a href="https://learn.adafruit.com/running-tensorflow-lite-on-the-raspberry-pi-4?view=all" target="_blank">Adafruit</a>, but we found that the model was much less reliable on common objects, and had an extremely limited set of items compared to the tutorial described above. The critical flaw in the better model was that it crashed the RPi when trying to run on the piTFT using <code>cv2</code>. A workaround for this was required.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The object detection section of our game is nearly identical to the tutorial script called <code>TFLite_detection_webcam.py</code>, with a few changes. One of the main changes is to switch from using the <code>cv2</code> library to display camera output, to using pygame to display to the piTFT. In order to do this, we found a great resource from a past <a href="https://courses.ece.cornell.edu/ece5990/ECE5990_Fall15_FinalProjects/Andre_Heil/ece5990_final_report/avh34_jr986.html" target="_blank">ECE 5990 student project</a> for a face-recognition system. They used the cv2 library to write to a temporary file, which is then read back in and displayed in the usual pygame fashion by blitting to the display surface and updating periodically. The frame itself is also rotated 90 degrees to match the orientation of the camera since it is wrapped around the side, instead of the top, of our RPi console.
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#ghk48: rotate to align with our setup</span>
frame <span style="color: #333333">=</span> cv2<span style="color: #333333">.</span>rotate(frame, cv2<span style="color: #333333">.</span>cv2<span style="color: #333333">.</span>ROTATE_90_COUNTERCLOCKWISE)

<span style="color: #888888">#ghk48: write to temp file so pygame can read and display</span>
cv2<span style="color: #333333">.</span>imwrite(<span style="background-color: #fff0f0">&#39;./tmp.bmp&#39;</span>, frame) <span style="color: #888888">#write frame</span>
img <span style="color: #333333">=</span> pygame<span style="color: #333333">.</span>image<span style="color: #333333">.</span>load(<span style="background-color: #fff0f0">&#39;./tmp.bmp&#39;</span>) <span style="color: #888888">#read frame</span>
win<span style="color: #333333">.</span>fill((<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>)) <span style="color: #888888">#clear screen</span>
win<span style="color: #333333">.</span>blit(img, (<span style="color: #0000DD; font-weight: bold">0</span>,<span style="color: #0000DD; font-weight: bold">0</span>)) <span style="color: #888888">#add frame</span>
pygame<span style="color: #333333">.</span>display<span style="color: #333333">.</span>update()
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                The other major change is the capture of a single label from every frame during detection, and storing it in a global variable (<code>obj_capture</code>) for use in-game once control 
                is handed back to the player. Since we are gating for just the first label in the list of detected objects (<code>classes_obj[0]</code>) which meets a minimum detection threshold, it is recommended that the user try to have only a single type of object detected in-frame when the game state is switched back to the character-controlled screen. When control returns (see <code>switch_state</code> under <a href="#userinput">User input</a>), the detected object is compared to the labels stored in three lists: one to acquire armor in the game, one for the weapon, and one for the apple. If the detected label is in one of these lists, an item is spawned in game with the appropriate characteristics and image asset. 
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #008800; font-weight: bold">if</span> (<span style="color: #007020">len</span>(scores)<span style="color: #333333">&gt;</span><span style="color: #0000DD; font-weight: bold">0</span> <span style="color: #000000; font-weight: bold">and</span> (scores[<span style="color: #0000DD; font-weight: bold">0</span>]<span style="color: #333333">&gt;</span>min_conf_threshold)):
    obj_capture <span style="color: #333333">=</span> labels[<span style="color: #007020">int</span>(classes_obj[<span style="color: #0000DD; font-weight: bold">0</span>])]
<span style="color: #008800; font-weight: bold">else</span>:
    obj_capture <span style="color: #333333">=</span> <span style="background-color: #fff0f0">&quot;none&quot;</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Because the object detection is based on a pre-trained model, the potentially detected labels are contained in a text file listing inside the folder <code>Sample_TF_Lite_model</code>. For the apple object to spawn, an "apple", "banana", or "orange" must be in-frame and detected. For a piece of armor, an "umbrella", "tie", or "backpack", will do. Finally, in order to get a dagger in the game, a "knife" or "scissors" must be visible and detected. 
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left; background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#recognizable objects taken from &quot;lablemap.txt&quot; in Sample_TFLite_model</span>
recog_knife <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;knife&quot;</span>, <span style="background-color: #fff0f0">&quot;scissors&quot;</span>]
recog_fruit <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;apple&quot;</span>,<span style="background-color: #fff0f0">&quot;banana&quot;</span>,<span style="background-color: #fff0f0">&quot;orange&quot;</span>]
recog_armor <span style="color: #333333">=</span> [<span style="background-color: #fff0f0">&quot;umbrella&quot;</span>,<span style="background-color: #fff0f0">&quot;backpack&quot;</span>,<span style="background-color: #fff0f0">&quot;tie&quot;</span>]

<span style="color: #008800; font-weight: bold">def</span> <span style="color: #0066BB; font-weight: bold">drop_item_noncb</span>():
    <span style="color: #008800; font-weight: bold">global</span> all_objects
    <span style="color: #008800; font-weight: bold">global</span> disp_objects
    <span style="color: #008800; font-weight: bold">global</span> obj_capture
    <span style="color: #008800; font-weight: bold">if</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_knife):
        knife <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>weapon(knife_im_l, knife_im, <span style="background-color: #fff0f0">&quot;knife&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #007020">True</span>, <span style="color: #0000DD; font-weight: bold">10</span>) <span style="color: #888888">#new item</span>
        knife<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(knife) <span style="color: #888888">#add to screen</span>
    <span style="color: #008800; font-weight: bold">elif</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_fruit):
        apple <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>item(apple_im, <span style="background-color: #fff0f0">&quot;apple&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #0000DD; font-weight: bold">30</span>, <span style="color: #007020">False</span>) <span style="color: #888888">#new item</span>
        apple<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(apple) <span style="color: #888888">#add to screen</span>
    <span style="color: #008800; font-weight: bold">elif</span>(obj_capture <span style="color: #000000; font-weight: bold">in</span> recog_armor):
        shirt <span style="color: #333333">=</span> classes<span style="color: #333333">.</span>armor(armor_im, <span style="background-color: #fff0f0">&quot;armor&quot;</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">310</span>, <span style="color: #0000DD; font-weight: bold">50</span>, <span style="color: #0000DD; font-weight: bold">15</span>, <span style="color: #0000DD; font-weight: bold">15</span>, <span style="color: #007020">True</span>, <span style="color: #0000DD; font-weight: bold">10</span>, <span style="background-color: #fff0f0">&quot;cold&quot;</span>, <span style="background-color: #fff0f0">&quot;torso&quot;</span>) <span style="color: #888888">#new item</span>
        shirt<span style="color: #333333">.</span>speedx <span style="color: #333333">=</span> <span style="color: #333333">-</span><span style="color: #0000DD; font-weight: bold">10</span> <span style="color: #888888">#thrown in</span>
        disp_objects<span style="color: #333333">.</span>append(shirt) <span style="color: #888888">#add to screen</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                <figure>
                <img class="img-rounded" src="pics/orange_detect.png" alt="RPi front" style="width:30%;">
                <img class="img-rounded" src="pics/apple_frame.png" alt="RPi front" style="width:30%;"><br>
                <img class="img-rounded" src="pics/tie_detect.png" alt="RPi front" style="width:30%;">
                <img class="img-rounded" src="pics/armor_frame.png" alt="RPi front" style="width:30%;"><br>
                <img class="img-rounded" src="pics/scissors_detect.png" alt="RPi front" style="width:30%;">
                <img class="img-rounded" src="pics/sword_frame.png" alt="RPi front" style="width:30%;"><br>
                <figcaption>Examples of a detected object, along with its spawned item.</figcaption>
                </figure><br>
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                These were the most appropriate labels that the model was already trained upon, so the player must find these objects through trial and error. While it takes time, training one's own custom model is also possible, and is explained by <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">EdjeElectronics</a> in their very informative tutorial.
              </p>
              <h3>Main game logic and structure</h3>
              <h4>Game state-machine</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The game state machine cycles through just a few possible game states. The first is the title screen, which merely shows the title of the game in basic
                text near the middle of the piTFT. The second game state is the main playable section, with a moveable character, item acquisition, collision detection, and
                environmental effects. The third game state is the object-detection phase, which is triggered when a user presses the appropriate button on the piTFT. This state
                displays the camera's view on the piTFT and draws bounding boxes around detected objects in-frame using TensorFlow-Lite. Pressing the same button that triggered this state hands control back to the second game state, where the player gains control of their character again. Finally, the end screen state shows the "You Died" text, indicating that the game is lost. The end of the game is triggered by either 1) a loss of all of one's health or 2) falling off of the level 1 platform, and therefore off-screen. This game state also clear's the character's inventory in order to respawn the hero back onto the screen.<br><br>
                In pseudo-code form, the basic format is shown below:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%"><span style="color: #888888">#finite state machine</span>
GAME_STATE <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">4</span>
GAME_PLAY <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">1</span>
OBJ_DETECT <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">2</span>
END_SCREEN <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">3</span>
MENU_SCREEN <span style="color: #333333">=</span> <span style="color: #0000DD; font-weight: bold">4</span>

<span style="color: #008800; font-weight: bold">while</span> run : <span style="color: #888888">#main game loop</span>
    clock<span style="color: #333333">.</span>tick(<span style="color: #0000DD; font-weight: bold">40</span>)
    <span style="color: #008800; font-weight: bold">if</span> GAME_STATE<span style="color: #333333">==</span>MENU_SCREEN:
        <span style="color: #888888">#display main title</span>
        <span style="color: #888888">#delay for a couple seconds</span>
        GAME_STATE <span style="color: #333333">=</span> GAME_PLAY
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>END_SCREEN:
        <span style="color: #888888">#display end screen with appropriate delays</span>
        <span style="color: #888888">#reset hero and add back to the displayable objects</span>
        GAME_STATE <span style="color: #333333">=</span> MENU_SCREEN
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>GAME_PLAY:
        <span style="color: #888888">#check for touchscreen press to trigger jump</span>
        <span style="color: #888888">#check for environment match to decrement health</span>
        <span style="color: #888888">#check for end state based on health&lt;=0 or y-position below the &quot;floor&quot;</span>
            <span style="color: #888888">#clear item inventory if the hero has died</span>
            <span style="color: #888888">#remove the hero itself</span>
            GAME_STATE <span style="color: #333333">=</span> END_SCREEN
        <span style="color: #888888">#move everything in the x direction</span>
        <span style="color: #888888">#check for x collisions</span>
        <span style="color: #888888">#move everything in the y direction</span>
        <span style="color: #888888">#check for y collisions</span>
        <span style="color: #888888">#update the screen</span>
    <span style="color: #008800; font-weight: bold">elif</span> GAME_STATE<span style="color: #333333">==</span>OBJ_DETECT:
        <span style="color: #888888">#perform object detection with tutorial example</span>
        <span style="color: #888888">#draw all boxes around detected objects</span>
        <span style="color: #888888">#grab the first detected object for spawning items</span>
        <span style="color: #888888">#write the frame rate on the frame, rotate it 90 degrees, and store in a temporary file</span>
        <span style="color: #888888">#read in the frame with pygame, blit onto the screen, and update the display.</span>
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                Note that the object detection phase can only be triggered by a button press on the third button from the "bottom" of the piTFT. Through this game state logic, the entire game is controlled by the single user. Please see the description of the game logic itself in the section above, or feel free to read through the source code to see everything in action. The demonstration video linked at the top of the page should also give a good sense of how the game state switching operates.
              </p>
              <h4></h4>
              <p style="text-align: left;padding: 0px 30px;">
                While the menu screen and the end title are not worth detailing here (they consist of a simple text render and pygame display), the <code>GAME_PLAY</code> and <code>OBJ_DETECT</code> states are worth a bit more explanation. The <code>GAME_PLAY</code> state relies on helper functions described in the <a href="#collisions">Collision Logic</a> section and defined in <code>classes.py</code>. After checking for a touch input, which triggers the hero's y-velocity to be set high, and after checking the environment against the hero's equipment (at a 3-second interval) to decrement health, the displayable objects are "moved" in the x direction based on their speed. Collisions due to this move are checked, and those movements are reversed if a collision occurs. They are then "moved" in the y-direction, checked for collisions, and reversed if necessary again. This effectively carries out the physics of our game, which first changes the position of the objects on-screen before showing that frame on the screen.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>OBJ_DETECT</code> phase follows the tutorial described in <a href="#objdetect">the object detection description</a> through the following process. First, a frame is taken from the video stream, which is an instance of a class designed by <a href="https://www.pyimagesearch.com/2015/12/28/increasing-raspberry-pi-fps-with-python-and-opencv/" target="_blank">Adrian Rosebrock</a> of PyImageSearch. This frame is resized and normalized as a preparation step for feeding into the TFLite model before detection is "performed." The results are stored, along with bounding boxes around the detected objects. For all of these detections, the results of the detection are used to draw boxes around, and label, those objects which the model is over 50% confident are in-frame. The label of the first object is stored for our game script, and then the frame, with bounding boxes, is stored ina temporary file and re-displayed by pygame, as desribed earlier.
              </p>
              <h3>Remote Connection Attempts</h3>
              <p style="text-align: left;padding: 0px 30px;">
                To expand the game to be a multiplayer experience, we tried multiple different methods which relied on the same basic example script that we wanted to adapt to our purposes. We tried to follow a set of tutorials from someone named TechWithTim, who maintains a website and a set of YouTube videos that detail the creation of web server and client python scripts. Our strategy was to run these examples to establish a connection first, and then adapt the game to work over the confirmed connection. The scripts use the <code>socket</code> and <code>pickle</code> libraries to connect two machines together.
              </p>
              <h4>Attempt 1: Opening a port on a home network</h4>
              <p style="text-align: left;padding: 0px 30px;">
                Our first attempt at an online connection was made by setting up port forwarding on Caeli's home router. Our hope was that by using the server's external IP instead of the local IP, we could use the local setup to connect two devices on different networks.
                The port was opened and set to direct all incoming traffic to the local IP address of the laptop serving as the server host. Then, an exception to the firewall settings was made on that laptop to allow incoming traffic on the designated port. This method resulted
                in a connection timeout error from the client script. Further probing using this website <a href="https://www.yougetsignal.com/tools/open-ports/" target="_blank">yougetsignal</a> indicated that despite all efforts to open the port, the port was still closed. After this point we decided to try a different
                approach that other students in the class seemed to be having success with.
              </p>
              <h4>Attempt 2: Host a server on a port on the class server</h4>
              <p style="text-align: left;padding: 0px 30px;">
                We also attempted to host a server on one RPi through the class server by opening a reverse ssh tunnel. First, we ran the following command in the terminal of either our laptop or the first RPi:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">ssh -R 6009:localhost:5000 <span style="color: #333333">[</span>netid<span style="color: #333333">]</span>@132.236.79.205
</pre></div><br>
              <p style="text-align: left;padding: 0px 30px;">
                This opens a connection between port 5000 on the device that issued the command, and opens port 6009 on the class server. To check that this connection is open and correct, Anthony Ngoma, a generous classmate, provided the following command which lists open ports on the class server:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">netstat -tulpn 
</pre></div><br>
              <figure>
                <img class="img-rounded" src="pics/ssh_connect.png" alt="banana" style="width:45%;">
                <img class="img-rounded" src="pics/ssh_confirm.png" alt="banana" style="width:45%;">
                <figcaption>After issuing the command to open the port, it is confirmed as open using the <code>netstat</code> command.</figcaption>
              </figure><br>
              <p style="text-align: left;padding: 0px 30px;">
                Once the creation of that open port was confirmed, we attempted to use the -L option of the ssh command to open a connection to a second device, this time from port 2000 on the second device, to the now open port 6009 on the class server:
              </p>
<!-- HTML generated using hilite.me --><div style="text-align: left;background: #ffffff; overflow:auto;width:auto;border:solid gray;border-width:.1em .1em .1em .8em;padding:.2em .6em;"><pre style="margin: 0; line-height: 125%">ssh -L 2000:localhost:6009 <span style="color: #333333">[</span>othernetid<span style="color: #333333">]</span>@132.236.79.205
</pre></div><br>

              <p style="text-align: left;padding: 0px 30px;">
                The server script is run on the first device, while the client script is run on the second device. We fed every permutation of IPv4 addresses to the scripts, as well as every port combination that we thought might solve the issue. However, no matter which ports we chose, which devices we tried to connect (even trying to connect a device to itself), nor what order of operations these commands followed, we were unable to establish a connection over the class server in this manner. Usually, the connection was rejected, giving us suspicion that the IP address or port numbers were incorrect. Sometimes, the connection merely timed out, indicating to us that our settings were likely correct, but that for some reason the connection was never fully established.
              </p>
              <h4>Attempt 3: Package and send data locally to demonstrate intent</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The last option was an attempt to, at the very least, show what our intent was with respect to packaging game data. The examples from TechWithTim were good, but were quite simplistic, including a game that transferred the positions of two red boxes on-screen in a small and very specific format. To pack our entire set of displayable game objects and send them over a network, we decided to use the pickle library. By following some online examples, as well as a very valuable forum post, we generated three scripts that run a single client-server line of communication. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>desktop_server.py</code> script creates a custom <code>Server</code> object to collect game data and display it in a window. It waits for a connection to a client, continuously recieves game data, and merely shows where those objects are on-screen, without the ability to control them.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>desktop_client.py</code> script creates a custom <code>Client</code> object which connects a desktop version of our game in a primitive form. User input is adapted to allow the use of the keyboard to move the player, and all game logic is performed locally in this script. At the end of a frame, <code>pickle</code> is used to package and send the entire displayable objects list to the server for display on the other end.  
                <figure>
                <img class="img-rounded" src="pics/laptop_multi.png" alt="banana" style="width:50%;">
                <figcaption>Running on a laptop, the transfer of data is much faster while the server mirrors what the client is controlling. Hitboxes are shown to ease debugging of potential collision issues due to lag between data transfers.</figcaption>
              </figure><br>
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The <code>rpi_client.py</code> script runs on the same logic as <code>desktop_client.py</code>, except that it can run without issue on the RPi, and the usual piTFT buttons can be used to control the game.
                <figure>
                <img class="img-rounded" src="pics/rpi_multi.png" alt="banana" style="width:50%;">
                <figcaption>Running on a Raspberry Pi, the transfer of data is a bit slow while the server mirrors what the client is controlling using the PiTFT buttons.</figcaption>
              </figure><br>
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Because <code>pickle</code> is not capable of packaging pygame surfaces, our original <code>classes.py</code> script needed to be adapted to <code>classes_multi.py</code>, which instead stores image file paths instead of a pre-generated pygame surface. Every time an object is drawn, the pygame surface can then be made locally on either the client or the server side to show it in a window.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                This multiplayer functionality, due to the fact that it is in the very preliminary stages of development, is contained within a separate <code>multiplayer</code> folder on our github page. By running first <code>sudo python3 desktop_server.py</code> on <i>either</i> the RPi or on a laptop, and then running <code>sudo python3 rpi_client.py</code> or <code>python desktop_client.py</code> <i>on the same machine</i>, a connection is established over a local network. This shows that the data sent by pickle is being packed, sent, and recieved without error. While this connection runs well on a laptop, there is some lag while running both scripts on the RPi, probably because the pygame surfaces are re-created every time an object is drawn, instead of being made once upon the intiialization of an object instead.
              </p>
      </div>

    <hr id='testing'>
      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Testing our design was a continuous process that happened every step of the way. Whenever significant changes were made to the source code, it was tested on the RPi to confirm that all elements of user input were still functioning properly. For most stages of development, we met as a team over zoom and began a <a href="https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare" target="_blank">VS Code LiveShare</a> session. This way, we could develop together on the same file without having to worry about github merge conflicts. Whenever asynchronous work was completed, or if development was performed on the RPi's themselves, we made sure to communicate about who had the latest version of the code to avoid conflicts. The first iteration of the use of Pygame was run on a laptop, but all subsequent development was first pushed to the github repository, pulled by either of us on a RPi, and run there to test.
              </p>
              <h3>Gravity and Drag and Collisions</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Testing the gravity and collision logic was by far the most grueling cycle of debugging. Whenever we made a small change, the results were tested by jumping around and making observations. Tweaks to hitboxes, the magnitude of gravity, the magnitude of item drag, and the placement of objects, all required a rapid cycle of small-change unit tests. Eventually, we settled on a gravity that was strong enough to require some skill to run and jump at the same time, but not so strong as to make navigation impossible. Drag was set such that items that pop-in from an object detection phase skid to a stop on the floor platform, without sliding all the way to the left. While the collision logic went through a number of iterations, the method we ended up with causes a nice animated jitter for all objects with physics. This gives a clear indication that those objects are "real" and an be interacted with.
                <figure>
                <img class="img-rounded" src="pics/apple_frame.png" alt="banana" style="width:30%;">
                <figcaption>Though the items are spawned with significant rightward speed, they come to a stop on the floor before reaching the block on the left.</figcaption>
              </figure><br></p>
              <p style="text-align: left;padding: 0px 30px;">
                We also tested the equipping-item logic many times. This involves detecting that the hero has collided with an equippable item, and then drawing it as an equipped image for the rest of the game instead of giving it the usual item physics.
                <figure>
                <img class="img-rounded" src="pics/sword_equipped.png" alt="banana" style="width:30%;">
                <figcaption>After working with small offsets from the hero's position, equipped armor and blades appear near the hero at all times.</figcaption>
              </figure><br>
              </p>
              <h3>Camera and well-detected objects</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Testing the potentially detected objects didn't take long, and some cross-referencing of the text file containing all the possible labels was necessary. We found that the label "person" was very reliably able to detect a person's hand or face. After testing a few of the items against what we have handy in our homes, we chose the objects that were detected consistently. For example, testing the camera on a butter knife was detected as "scissors" more often than "knife." This is due to the fact that it has the same texture/shine through the blade and handle. A kitchen knife with a darker handle would have been more reliable, but an actaul pair of scissors were detected easily as well. We also found that a lemon, shown in the demonstration video, was detected as an apple consistently enough for the demonstration. Note that this is only because Greg did not have apples nor bananas in his house at the time of testing. Both of those fruits, as well as clementines (detected as "orange"), can be identified by the object detection system.
                <figure>
                <img class="img-rounded" src="pics/banana_detect.png" alt="banana" style="width:30%;">
                <img class="img-rounded" src="pics/orange_detect.png" alt="orange" style="width:30%;"><br>
                <img class="img-rounded" src="pics/tie_detect.png" alt="tie" style="width:30%;">
                <img class="img-rounded" src="pics/scissors_detect.png" alt="scissors" style="width:30%;">
                <figcaption>Some examples of easily detected objects for use in-game. The fruit all spawn an apple, whereas the tie spawns armor, and the scissors spawn a blade.</figcaption>
              </figure><br>
              </p>
              <h3>Multiplayer testing/debugging</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Testing the multiplayer components, unlike the rest of the project, were much less fun to test and debug. The results of tests of this nature are much less visual, and have more to do with whether or not our settings are correct. Testing these server and client scripts was more about frequent communication between the two of us across networks, with screen sharing of some kind enabled to allow both of us to understand what was happening. By calling out when the server is open, and with what settings, we were able to try multiple permutations of the IP address and port fields to hunt down our problems. Using the command given to us by Anthony Ngoma also allowed us to test our ssh command to rule that out as a potential source of error. Working with the TA's over office hours also helped us aim some brain power into understanding which ports are meant to connect, and how.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Once we decided to go with a local option, porting the game script into either the desktop version of the client, or the raspberry pi client, was simple. However, two scripts were developed for use on a laptop in order to confirm that a test object was being transferred at all. This helped debug issues with our use of the <code>pickle</code> library, and with the socket connection as an isolated problem. The scripts <code>multi_server.py</code> and <code>multi_client.py</code> contained a single identical <code>tst_obj</code> with a few fields inside. They defined a custom <code>Server</code> and <code>Client</code> class, respectively. By opening a socket connection and just transferring this single test object from the client to the server, repeatedly, we were able to confirm that <code>pickle</code> was working in conjunction with <code>socket</code> to transfer our data.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Once the desktop and RPi version of the client, as well as the adapted server script, were complete, a bit of testing was required to make sure that user input on the desktop side was registered correctly. Also, due to the fact that pickle cannot package Pygame surfaces, some extra development had to be done to convert the <code>image</code> member field to an <code>imagepath</code> for each object on-screen. The hitboxes were also re-enabled, as seen in the demonstration video for the local multiplayer component, to debug collision issues and figure out if the hitboxes are accurate, or if bugs were a result of lag across the local connection.
              </p>
      </div>

    <hr id='result'>
      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">
                We certainly accomplished many of our goals with this project. The single player version of the game uses a camera to make an interactive experience for a user, and we were able to implement many elements of a game engine on our own, including some physics and collision detection, as well as environmental game effects. Using minimal hardware due to the remote nature of this semester was a success, since neither of us ran into significant issues getting the camera to operate properly. Additionally, the use of the PiTFT was a great success, since we both loved the small-computer-screen/handheld-gaming aesthetic of that device. While we were unable to completely implement a multiplayer version of the game exactly as promised, we made significant progress towards a great-than-local-network channel of communication, and learned a lot about networking on the way. Outside of that element, each piece of the project performed as expected.  
              </p>
              <figure>
                <img class="img-rounded" src="pics/concept_game.png" alt="concept" style="width:40%;">
                <img class="img-rounded" src="pics/button_identify.jpg" alt="final im" style="width:40%;"><br>
                <figcaption>Compared to our original game concept, we did a great job of going beyond the look and feel that we were aiming for.</figcaption>
              </figure><br>
              <p style="text-align: left;padding: 0px 30px;">
                Because of the condensed timeline this semester, we also practiced good project management by accomplishing milestones in an incremental manner every week. We had concrete goals to achieve, and although we did not adhere perfectly to the original schedule, we made intelligent choices to modify it along the way. There was always significant progress each week, either in the development of a new capability, or by implementing a solution to a previous week's problem. Scheduling synchronous meetings across time zones and busy schedules was difficult.
              </p>
      </div>

    <hr id='conclusion'>
      <div style="text-align:center;">
              <h2>Conclusion</h2>
              <p style="text-align: left;padding: 0px 30px;">
                We were able to accomplish a lot in just a few weeks despite the circumstances of this crazy semester under the quarantine conditions of the COVID-19 pandemic. The game that we created works as we intended, and there is a clear path forward towards the greater multiplayer goal. We were very pleased with the responsiveness of the device, both in moving and jumping, as well as the consistency of object detection, which works well given that it is running on the RPi 4. The result is a fun game platform with a lot of potential for level development. We also gained a greater appreciation for game development in general, and tried to approach the problem in a modular and expandable way. Level design based on the classes that we have created is easy and fun to do.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                If we had to do this project again, we would probably start with the multiplayer aspect of the game, since the game logic and object detection is now a problem that we know how to solve. We know that our attempts at multiplayer over multiple networks definitely did not work, but each of the attempts is still a valid direction to continue trying. We also know that checking for rectangle collisions ourselves was unneccessary, and does not work very well either. In order to expand collision logic to multiple physical items, a more efficient approach is required. We definitely learned that, although a lot of time was spent developing our own rectangle collision logic, that time was not wasted. Having attacked that problem and run into a roadblock made the development of our final collision detection logic much more robust and easier to implement.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                In the end, we had the most fun developing the game engine itself. That is, the collection and display of images that we get to select, enabling character movements/collisions, being able to change the gravity in this world, applying environmental effects, and organizing the level's obstacles and properties, was the most enjoyable part. This was the part of Lab 2 that intrigued us the most, since designing our own Motor class activated our creativity. The design elements of the game, how the object-oriented hierarchy is organized, what functions and variables are attributed to each object, and how that informs gameplay, all allow us to use our imaginations and come up with our own way of accomplishing tasks. We look forward to using the Raspberry Pi platform for development along these lines in the future.
              </p>
      </div>

    <hr id='future'>
      <div style="text-align:center;">
              <h2>Future Work</h2>
              <p style="text-align: left;padding: 0px 30px;">
                There are many different directions that this project could head in the future, and there are many elements that could be expanded for more functionality. The two main components of the game that could be improved are the game functions themselves, and the multiplayer component which we started.
              </p>
              <h3>Expanding the game</h3>
              <p style="text-align: left;padding: 0px 30px;">
                To expand game functionality, more game logic will have to be added to handle the additional components. However, we did make the class structure general enough that a few of them can be implemented without too much hassle.
              </p>
              <!-- <h4>Camera movement</h4> -->
              <p style="text-align: left;padding: 0px 30px;">
                To move the camera and the rest of the level along with the character, we gave our displayable objects both x and y positions as well as global x and y position fields. By keeping track of a camera position, we could use the global positions to check which objects in a broader list of level objects are "visible" and only display those. This would allow the camera to track the character across a set of global level coordinates, while the objects come into and out of that frame at the appropriate positions. 
              </p>
              <!-- <h4>Multiple levels/environments</h4> -->
              <p style="text-align: left;padding: 0px 30px;">
                Designing our first level was not difficult, and only took a few lines to create the platforms for the character to jump on. By creating multiple levels in the game, a transition from one level to another could be triggered by either the character reaching a certain global position, or based on collision with a special object like a door, or using a special item. 
              </p>
              <!-- <h4>Enemies and other moving assets</h4> -->
              <p style="text-align: left;padding: 0px 30px;">
                Creating intelligent enemies would be a difficult task, but one that would make the game much more interesting for a given player. Because the character class has an attack and defense field, the enemies could be made as characters which attempt to reach the hero's position, or follow a set trajectory. Adding in this other source of health-loss would also make the game more exciting for the player, who would now have to handle environmental effects as well as enemy onslaught.
              </p>
              <!-- <h4>Custom TensorFlow-Lite model</h4> -->
              <p style="text-align: left;padding: 0px 30px;">
                Training a custom TensorFlow-Lite model would allow us to create a more specific set of items for the player to detect. As it stands, only trial and error will be able to identify objects that will spawn a valid item in-game. Adding in features that indicate what a "good" item looks like, and limiting the set of detected objects so that as many as possible are "valid" for gameplay, will make the user experience much more pleasurable.
              </p>
              <!-- <h4>Menu Screen, Game Score, and Inventory Access</h4> -->
              <p style="text-align: left;padding: 0px 30px;">
                Right now, the menu screens are very basic, and the user has no access to inventory items, though even consumed apples are there in storage. Adding a feature which allows the user to access and view his/her inventory would make it easier to acquire more equippable items, and swap out armor for what is needed in the current environment.
              </p>
              <h3>Extension to multiplayer</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Of course, extending this game to a full multiplayer version that allows a connection to two separate devices across home networks would make the game much more exciting. Building in the game state to the transferred data would allow for one player to have full control of the game at a time, and would allow one user to be responsible for finding objects for the other to use in the game. Accomplishing game objectives together as a team is always more enjoyable than tackling them alone.
              </p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group_photo.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Group picture of Caeli and Greg.</h4>
              <p>
                All synchronous work was done over zoom using other collaboration tools like the Live Share feature of VS Code as well as github and Google Drive. A lot of asynchronous work was done due to scheduling conflicts and the time difference between the east and west Coast<br><br>
                <b>Group responsibilities:</b><br>
                  - Class and higher-level game logic design.<br>
                  - Image asset collection.<br>
                  <!-- - Objective, Introduction, Results, and Conclusion sections of the report.<br> -->
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/caeli_pic.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Caeli MacLennan</h3>
              <p class="lead">cam476@cornell.edu</p>
              <p>
                <p style="text-align: left;padding: 0px 30px;">
                  - Initial concept, layout, and functionality map. <br>
                  - Collision logic.<br>
                  - Port Forwarding Attempt (attempt 1).<br>
                  - Wrote website setions on the above as well as those for the game classes and functions.<br>
                  - Investigated object pickling and network connections.<br>
                </p>
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
              <h3>Gregory Kaiser</h3>
              <p class="lead">ghk48@cornell.edu</p>
              <p style="text-align: left;padding: 0px 30px;">
                - Designed the state machine and menu cycle.<br>
                - Developed and tested TFLite capabilities and integrated them into game logic.<br>
                - Adapted TFLite to run on the piTFT, and designed item spawning logic (checking for detected objects).<br>
                - Attempted to host a web server on the class server using ssh commands (Attempt 2).<br>
                - Wrote desktop_server.py, desktop_client.py, and rpi_client.py to establish object transfer over local network (Attempt 3).<br>
                - Wrote website sections on the above, as well as the Testing, Hardware, and Future Work sections.<br>
                - Filmed/edited demonstration video.<br>
              </p>
          </div>
      </div>

    <hr id='BOM'>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li><a href="https://www.adafruit.com/product/1601" target="_blank">Adafruit PiTFT 1.8'' TFT and Touchscreen</a> $35.00</li>
              <li><a href="https://www.amazon.com/Raspberry-Pi-Camera-Module-Megapixel/dp/B01ER2SKFS/ref=sr_1_3?dchild=1&keywords=raspberry+pi+camera&qid=1608266423&sr=8-3" target="_blank">Raspberry Pi Camera V2</a> $25.00</li>
          </ul>
          <h3>Total: $95.00 ($60.00 if PiTFT not included)</h3>
      </div>
      <hr id='references'>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md#part-1---how-to-set-up-and-run-tensorflow-lite-object-detection-models-on-the-raspberry-pi" target="_blank">Evan, EdjeElectronics, TensorFlow-Lite-Object-Detection.</a><br>
          <a href="https://courses.ece.cornell.edu/ece5990/ECE5990_Fall15_FinalProjects/Andre_Heil/ece5990_final_report/avh34_jr986.html" target="_blank">Jingyao Ren and Andre Heil, Face Recognition System.</a><br>
          <a href="https://www.youtube.com/watch?v=-3B1v-K1oXE" target="_blank">TechWithTim, Online Multiplayer Game With Python - Sockets and Networking: </a><br>
          <a href="https://pygame.org" target="_blank">Pygame</a><br>
          <a href="https://courses.ece.cornell.edu/ece5990/ECE5725_Fall2019_Projects/Dec_13_Demo/Legend%20of%20Pielda/Monday_gx55_jf832_.LegendOfPielda/index.html " target="_blank">Feng, Jie, Xie, Gengqiao. “Final Project of ECE 5725: Legend of Pielda.”</a><br>
          <a href="https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/7" target="_blank">Picamera Libraries.</a><br>
          <a href="https://www.techwithtim.net/tutorials/game-development-with-python/side-scroller-pygame/background/" target="_blank">TechWithTim, Pygame Side Scroller.</a><br>
          <a href="https://github.com/techwithtim/Network-Game-Tutorial" target="_blank">TechWithTim, LAN multiplayer game.</a><br>
          <a href="https://www.techwithtim.net/tutorials/python-online-game-tutorial/server/" target="_blank">TechWithTim, Online server multiplayer game.</a><br>
          <a href="https://learn.adafruit.com/adafruit-pitft-28-inch-resistive-touchscreen-display-raspberry-pi/pitft-pygame-tips" target="_blank">Adafruit Wheezy downgrade.</a><br>
          <!-- <a href="https://pygame.org" target="_blank">Pygame</a><br> -->
      </div>
      <div style="font-size:18px">
          <h2>Image sources (in-game)</h2>
          <a href="https://banner2.cleanpng.com/20180403/yge/kisspng-knife-computer-icons-pixel-art-pixel-art-5ac406eae6de59.9927812015227962669457.jpg" target="_blank">Knife sprite</a><br>
          <a href="https://www.seekpng.com/png/full/819-8194450_minecraft-diamond-chestplate-chestplate-minecraft.png" target="_blank">Armor sprite</a><br>
          <a href="https://www.101computing.net/wp/wp-content/uploads/Applepix.png" target="_blank">Apple sprite</a><br>
          <a href="https://static.wikia.nocookie.net/nintendo/images/6/63/Brick_Block.png/revision/latest/scale-to-width-down/340?cb=20151206062204&path-prefix=en" target="_blank">Brick sprite</a><br>
          <a href="https://i.redd.it/phrlrn16jb101.png" target="_blank">Background image</a><br>
          <a href="https://cdn.shopify.com/s/files/1/1061/1924/products/Praying_Emoji_ios10_020ec88e-ee33-496d-a95a-df23243cebf4_grande.png?v=1571606092" target="_blank">"Pray" emoji</a><br>
          <a href="https://img.icons8.com/plasticine/2x/arrow.png" target="_blank">Arrow icon</a><br>
          <a href="https://lh3.googleusercontent.com/proxy/A_nefWTpQPtq3HPrmivxU88LsduCnzEkatrug9MtuxOiBTupBAvEN9Y8XUnl-Kz27k1HOK0ivP8vYTMCC1qEVRsFcNWMUdpd8iPDQ8djKcEs" target="_blank">"Quit" icon</a><br>
          <a href="https://www.gameart2d.com/the-boy---free-sprites.html?fbclid=IwAR0tTHEqI8NAzxDeqf6dv46RdYfRzCcc6WLgiOOXJFw-WXmWvYZazSpb_jU" target="_blank">Hero "flatboy" images</a><br>
          <a href="https://en.wikipedia.org/wiki/File:Ground_(front_layer).png" target="_blank">Ground image</a><br>
      </div>

    <hr id='appendix'>

      <div class="row">
              <h2>Code Appendix</h2>
              Our github repository, <a href="https://github.com/gregoryKaiser/ece5725_fp" target="_blank">ece5725_fp</a>, should have the scripts below as well as the other resources needed to run the game.
              <h3>game_and_detect_update.py</h3>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>

              <h3>classes.py</h3>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>

              <h3>desktop_server.py</h3>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>

              <h3>desktop_client.py</h3>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>

              <h3>rpi_client.py</h3>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->

    <!-- <figure>
      <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
      <figcaption>hello</figcaption>
    </figure> -->



    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
