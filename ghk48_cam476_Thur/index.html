
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>It's Dangerous To Go Alone</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">It's Dangerous To Go Alone...</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#obj">Project Objective</a></li>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#design">Design</a></li>
            <li><a href="#drawings">Drawings</a></li>
            <li><a href="#testing">Testing</a></li>
            <li><a href="#result">Result</a></li>
            <li><a href="#conclusion">Conclusion</a></li>
            <li><a href="#future">Future Work</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
      <div class="starter-template">
        <h1>ECE 5725 Final Project: It's Dangerous To Go Alone</h1>
        <p class="lead">
          An interactive game concept. <br>By: Gregory Kaiser (ghk48) and Caeli MacLennan (cam476). <br> December 18<sup>th</sup> 2020.
        </p>
      </div>

      <hr>
      <div class="center-block">
          <iframe width="640" height="360" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allowfullscreen></iframe>
          <h4 style="text-align:center;">Demonstration Video</h4>
      </div>

      <hr id='obj'>
      <div class="row">
          <!-- <div class="col-md-4" style="text-align:center;">
          <img class="img-rounded" src="pics/1.jpg" alt="Generic placeholder image" width="240" height="240">
          </div> -->
          <div class="col-md-8" style="font-size:18px;">
          <h2>Project Objective:</h2>
          <p style="text-align: left;padding: 0px 30px;">
            The objective of "It's Dangerous To Go Alone" is to demonstrate an interactive adventure game which requires 
            one to obtain items through the detection of real objects using a Raspberry Pi (RPi) camera. Additionally, we sought to demonstrate
            a remote connection for two Raspberry Pi's to communicate, allowing for a fun game to be played while social distancing in 2020. 
            Additionally, we wanted to exercise our object-oriented programming skills to develop a starting point for future game level design and feature
            additions.
          </p>
          </div>
      </div>

      <hr id="intro">
      <div style="text-align:center;">
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Playing adventure games is a lot of fun, especially when the world is so absorbing that one gets lost in the universe's rules and quirky limitations.
                From the touchscreen of the original Nintendo DS, to the motion-controls of the Wii platform, however, there are a number of examples of novel user 
                input that demonstrate its utility and potential for better user engagement. Along these lines, we wanted items in our game to be acquired by finding similar
                items in real life that are recognized by a camera system. Thanks to recent developments in image processing and machine learning, we can use a lightweight 
                object detection model to pick up on a limited set of real objects, and then spawn them for use by the character. We also attempted to make this project multiplayer 
                by trying a few methods of data transfer over our home networks.
              </p>
      </div>

    <hr id='design'>
      <div style="text-align:center;">
              <h2>Design</h2>
              <p style="text-align: left;padding: 0px 30px;">
                Our design for this project occurred mostly in software, where we tried to make an expandable platform for generic level creation.
                Some changes were made in order to ensure that the camera was oriented correctly in-game, but we otherwise had very little trouble interfacing
                with the camera module.
              </p>
              <h3>Hardware</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Though we originally had aspirations for a more interesting hardware setup, the end-product consists of only a RPi and camera module. The camera's 
                ribbon cable is wrapped around the body of the RPi case and is mounted to its underside. The device is held in both hands, in a portrait orientation 
                with the piTFT buttons on the right.
              </p>
              <h3>PyGame and Class Design</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Object types and functionality</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>User input</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The piTFT provides the full user interface for a player. Two of the buttons are used for moving the character right and left, by 
                triggering callback functions that call the character's movement member functions. These buttons are denoted by icons displayed next to them
                on-screen. The RPi.GPIO library is used to connect these buttons to their
                functionality, and they are triggered using both the rising and falling edge of the button signal. This way, when the button is pressed down, the
                character moves in one direction, and when it is released, the character is halted. By tapping on the touchscreen, the character jumps in the air. 
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Another piTFT button is used to trigger a callback function that switches control to the camera on the back of the device. This changes the game state to 
                detect objects for the user to acquire in-game. The final button on the "top" of the piTFT (closest to the power source) is a simple quit button to allow the user to 
                end the game entirely.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Of course, the player is also responsible for finding items in real life for the game to detect, and experimenting to find our limited set of detectable objects.
              </p>
              <h4>Collision logic</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h3>Object Detection with TensorFlow-Lite</h3>
              <p style="text-align: left;padding: 0px 30px;">
                Objects are detected using TensorFlow-Lite by following closely a tutorial from [name and link]. 
              </p>
              <h4>Tutorial-based setup</h4>
              <p style="text-align: left;padding: 0px 30px;">
                In this tutorial, the Raspberry Pi is first updated in order to run the appropriate testing scripts.
                In order not to cause conflicts between the packages required by TensorFlow-Lite and the Raspberry Pi, a virtual environment is set up and then the required libraries are acquired through 
                a script provided by the tutorial. In order to test the object detection itself, the github repository has example scripts which can confirm that the necessary pieces
                are in place and working properly.
              </p>
              
              <h4>Wheezy downgrade</h4>
              <p style="text-align: left;padding: 0px 30px;">
                Because the update mentioned above causes issues when using pygame to control the piTFT, the downgrade performed in Lab 2 of ECE 5725 is repeated.
                [condensed wheezy downgrade explanation] 
              </p>
              <h4>Adapted to run on the piTFT screen</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The object detection section of our game is the same as the tutorial script, with a few minor changes. One of the main changes is to switch from using the cv2 library 
                to display camera output to the Raspberry Pi desktop, to using pygame to display to the piTFT. In order to do this, we found a great resource from a past student project 
                which used the cv2 library to write to a temporary file, which is then read back in and displayed in the usual pygame fashion by blitting ot the display surface and updating
                periodically.
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                The other major change is the capture of a single label from every frame during detection, and storing it in a global variable for use in-game once control 
                is handed back to the player. By gating for just the first label in the list of detectable objects which meets a minimum detection threshold, it is recommended that the 
                user try to have only a singel type of object detected in-frame when the game state is switched back to the character-controlled screen. When control returns, the detected 
                object is compared to the labels stored in three lists: one to acquire armor in the game, one for the weapon, and one for the apple. If the detected label is in one of 
                these lists, an item is spawned in game with the appropriate characteristics and image asset.  
              </p>
              <p style="text-align: left;padding: 0px 30px;">
                Because the object detection is based on a pre-trained model, the potentially detected labels are contained in a text file listing inside the folder <code>Sample_TF_Lite_model</code>. 
                For the apple object to spawn, an "apple", "banana", or "orange" must be in-frame and detected. For a piece of armor, an "umbrella", "tie", or "backpack", will do. 
                Finally, in order to get a knife in the game, a "knife" or "scissors" must be visible and detected. These were the most appropriate labels that the model was already
                trained upon, so the player must find these objects through trial and error. While it takes time, training one's own custom model is also possible, and is explained by [name] 
                in their very informative tutorial.
              </p>
              <h3>Main game logic and structure</h3>
              <p style="text-align: left;padding: 0px 30px;">
                [explanation of classes.py and game_and_detect_update.py and how things are structured in the main source code]
              </p>
              <h4>Game state-machine</h4>
              <p style="text-align: left;padding: 0px 30px;">
                The game state machine cycles through just a few possible game states. The first is the title screen, which merely shows the title of the game in basic
                text near the middle of the piTFT. The second game state is the main playable section, with a moveable character, item acquisition, collision detection, and
                environmental effects. The third game state is the object-detection phase, which is triggered when a user presses the appropriate button on the piTFT. This state
                displays the camera's view on the piTFT and draws bounding boxes around detected objects in-frame using TensorFlow-Lite. Pressing the same button that triggered this state hands
                control back to the second game state, where the player gains control of their character again. Finally, the end screen state shows the "You Died" text, indicating that the game is lost.
                It is triggered by either 1) a loss of all of one's health or 2) falling off of the level 1 platform, and therefore off-screen. This game state also clear's the character's inventory
                in order to respawn the hero back onto the screen.
              </p>
              <h3>Remote Connection Attempts</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Attempt 1: Opening a port on a home network</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Attempt 2: Host a server on a port on the class server</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Attempt 3: Package and send data locally to demonstrate intent</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
      </div>

    <hr id='drawings'>
      <div style="text-align:center;">
              <h2>Drawings</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This is the drawings section.
              </p>
      </div>

    <hr id='testing'>
      <div style="text-align:center;">
              <h2>Testing</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This is the testing section. Mention vs code workflow here as well
              </p>
              <h3>Gravity and Drag and Collisions</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h3>Camera and well-detected objects</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h3>Multiplayer testing/debugging</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
      </div>

    <hr id='result'>
      <div style="text-align:center;">
              <h2>Result</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This is the results section. 
              </p>
      </div>

    <hr id='conclusion'>
      <div style="text-align:center;">
              <h2>Conclusion</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This is the conclusion section.
              </p>
      </div>

    <hr id='future'>
      <div style="text-align:center;">
              <h2>Future Work</h2>
              <p style="text-align: left;padding: 0px 30px;">
                This is the future work section.
              </p>
              <h3>Expanding the game</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Camera movement</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Multiple levels/environments</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Enemies and other moving assets</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Custom TensorFlow-Lite model</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h4>Menu Screen, Game Score, and Inventory Access</h4>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
              <h3>Extension to multiplayer</h3>
              <p style="text-align: left;padding: 0px 30px;">
                
              </p>
      </div>

    <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group_photo.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Group picture of Caeli and Greg.</h4>
              <p>
                All synchronous work was done over zoom using other collaboration tools like the Live Share feature of VS Code as well as github and Google Drive.<br><br>
                <b>Group responsibilities:</b>
                  <li>Class design and member function tweaking.</li>
                  <li>Image asset collection.</li>
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/a.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Caeli MacLennan</h3>
              <p class="lead">cam476@cornell.edu</p>
              <p>
                [describe contributions in paragraphical or list form]
              </p>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
              <h3>Gregory Kaiser</h3>
              <p class="lead">ghk48@cornell.edu</p>
              <p>
                <li>Designed the state machine and menu cycle.</li>
                <li>Confirmed TFLite capabilities and integrated them into game logic.</li>
                <li>Adapted TFLite to run on the piTFT, and designed item spawning logic (checking for detected objects).</li>
                <li>Attempted to host a web server on the class server using ssh commands (Attempt 2).</li>
                <li>Wrote desktop_server.py, desktop_client.py, and rpi_client.py to establish object transfer over local network (Attempt 3).</li>
                <li>Edited demonstration video.</li>
              </p>
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li>Raspberry Pi Camera V2 $25.00</li>
              <a href="https://www.adafruit.com/product/1463"><li>NeoPixel Ring - $9.95</li></a>
              <li>LEDs, Resistors and Wires - Provided in lab</li>
          </ul>
          <h3>Total: $69.95</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="http://www.micropik.com/PDF/SG90Servo.pdf">Tower Pro Servo Datasheet</a><br>
          <a href="http://getbootstrap.com/">Bootstrap</a><br>
          <a href="http://abyz.co.uk/rpi/pigpio/">Pigpio Library</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>

      </div>

    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->

    <!-- <figure>
      <img class="img-rounded" src="pics/greg_pic.png" alt="Headshot of Greg" width="240" height="240">
      <figcaption>hello</figcaption>
    </figure> -->



    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
